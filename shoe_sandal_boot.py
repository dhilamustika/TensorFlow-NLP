# -*- coding: utf-8 -*-
"""Shoe-Sandal-Boot.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Wt5vUNRGirbECiMYoNDOvim3xIghc_bA

# Image Classification
Python code for classifying shoe, sandal, and boot images


---


Nadhilah Mustikarini (1494037162100-1057)

@20221208
"""

from google.colab import files

uploaded = files.upload()

# extract the dataset
import zipfile, os
local_zip = '/content/Shoe-Sandal-Boot.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/content')
zip_ref.close()

os.listdir('/content/Shoe-Sandal-Boot')

# split folder into train and validation sets

!pip install split-folders

import splitfolders
splitfolders.ratio('/content/Shoe-Sandal-Boot', output="/content/Shoe-Sandal-Boot/dataset-split", seed=1337, ratio=(0.8, 0.2))

# check the number of files in each directory

print('Train Set (80%)',
      '\nTotal shoe images:', len(os.listdir('/content/Shoe-Sandal-Boot/dataset-split/train/Shoe')),
      '\nTotal sandal images:', len(os.listdir('/content/Shoe-Sandal-Boot/dataset-split/train/Sandal')),
      '\nTotal boot images:', len(os.listdir('/content/Shoe-Sandal-Boot/dataset-split/train/Boot')))

print('\nValidation Set (20%)',
      '\nTotal shoe images:', len(os.listdir('/content/Shoe-Sandal-Boot/dataset-split/val/Shoe')),
      '\nTotal sandal images:', len(os.listdir('/content/Shoe-Sandal-Boot/dataset-split/val/Sandal')),
      '\nTotal boot images:', len(os.listdir('/content/Shoe-Sandal-Boot/dataset-split/val/Boot')))

# define directory names for train and validation sets
base_dir = '/content/Shoe-Sandal-Boot/dataset-split'
train_dir = os.path.join(base_dir, 'train')
validation_dir = os.path.join(base_dir, 'val')

# Commented out IPython magic to ensure Python compatibility.
# display some sample images
from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline
img = image.load_img('/content/Shoe-Sandal-Boot/Boot/boot (10).jpg')
imgplot = plt.imshow(img)

# image augmentation process on each sample in the dataset

from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(
                    rescale= 1./255,
                    rotation_range=20,
                    horizontal_flip=True,
                    shear_range=0.2,
                    fill_mode='nearest')

validation_datagen = ImageDataGenerator(
                    rescale=1./255)

# image generator

train_generator = train_datagen.flow_from_directory(
        train_dir,
        target_size=(150,150),
        batch_size=4,
        class_mode='categorical')

validation_generator = validation_datagen.flow_from_directory(
        validation_dir,
        target_size=(150,150),
        batch_size=4,
        class_mode='categorical')

# build a model

import tensorflow as tf

model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150,150,3)),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Dropout(0.2),
#    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
#    tf.keras.layers.MaxPooling2D(2,2),
#    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Dropout(0.2),
#    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),
#    tf.keras.layers.MaxPooling2D(2,2),
#    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Conv2D(512, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation='relu'),
#    tf.keras.layers.Dropout(0.4),
    tf.keras.layers.Dense(3, activation='softmax')
])

model.summary()

# compile the model 
model.compile(optimizer=tf.optimizers.Adam(),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# train the model

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy')>0.9):
      print("\nAccuracy has reached >90%!")
      self.model.stop_training = True

callbacks = myCallback()
history = model.fit(
      train_generator,
      steps_per_epoch=30,
      epochs=50,
      validation_data=validation_generator,
      validation_steps=10,
      verbose=2)

# plot the accuracy of the model
import matplotlib.pyplot as plt
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

# plot the loss of the model
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

# save the model in SavedModel format
export_dir = 'saved_model/'
tf.saved_model.save(model, export_dir)

# convert SavedModel to shoes.tflite

import pathlib
converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)
tflite_model = converter.convert()

tflite_model_file = pathlib.Path('shoes.tflite')
tflite_model_file.write_bytes(tflite_model)